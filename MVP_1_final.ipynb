{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# üèä‚Äç‚ôÄÔ∏è MVP ‚Äî Classifica√ß√£o de Medalhistas em Nata√ß√£o Ol√≠mpica (1912‚Äì2020)\n\n**Autora:** Luiza Oliveira Lima  \n**Objetivo:** Prever se um(a) atleta conquistar√° **medalha** (ouro, prata, bronze) em provas ol√≠mpicas de nata√ß√£o, a partir de atributos da prova/atleta.\n\n**Resumo executivo:** Utilizamos o dataset p√∫blico *Olympic Swimming History (1912‚Äì2020)*. O melhor desempenho foi obtido com **XGBoost**. Ap√≥s *tuning* e ajuste do **threshold = 0.40**, priorizamos **recall** para medalhistas, mantendo acur√°cia competitiva. Vari√°veis mais relevantes: **Team (pa√≠s)**, **Relay?**, **Stroke**, **Distance**, **Year**.\n\n> **Reprodutibilidade:** links de dados via URL, seeds fixas, pipelines `sklearn`, RandomizedSearchCV (CV=5). Notebook executa do in√≠cio ao fim.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Importa√ß√µes, Seeds & Config\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "RANDOM_STATE = 42\nTHRESHOLD = 0.40\nTOP_N = 10\n\nimport warnings, numpy as np, pandas as pd, matplotlib.pyplot as plt\nwarnings.filterwarnings(\"ignore\")\nnp.random.seed(RANDOM_STATE)\n\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (accuracy_score, classification_report, roc_auc_score,\n                             confusion_matrix, ConfusionMatrixDisplay,\n                             precision_recall_fscore_support)\nimport xgboost as xgb\nimport re\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Carga dos Dados\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Fonte (URL RAW no GitHub)\nURL = \"https://raw.githubusercontent.com/datasciencedonut/Olympic-Swimming-History-1912-to-2020-/main/Olympic_Swimming.csv\"\n\ndf = pd.read_csv(URL)\nprint(\"Dimens√µes:\", df.shape)\ndf.head()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. EDA m√≠nima\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df.info()\nprint(\"\\nNulos por coluna:\\n\", df.isnull().sum())\nprint(\"\\nDistribui√ß√£o de Rank (1=ouro, 2=prata, 3=bronze):\")\nprint(df[\"Rank\"].value_counts().sort_index())\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Engenharia de Atributos ‚Äî Target & Dist√¢ncia\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Alvo: Medalha = 1 se Rank <=3, sen√£o 0\ndf['Medalha'] = (df['Rank'] <= 3).astype(int)\n\n# Dist√¢ncia num√©rica (inclui revezamentos 4x100 -> 400)\ndef convert_distance(x: str) -> int:\n    x = str(x)\n    if \"x\" in x:  # revezamento (ex: 4x100)\n        a,b = x.split(\"x\")\n        return int(a) * int(b)\n    return int(re.sub(\"[^0-9]\", \"\", x))\n\ndf['Distance_value'] = df['Distance (in meters)'].apply(convert_distance)\n\n# Checagens r√°pidas\nprint(df[['Distance (in meters)', 'Distance_value']].head(8))\nprint(\"\\nPropor√ß√£o da classe Medalha:\\n\", df['Medalha'].value_counts(normalize=True).rename('proportion'))\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Split & Pipeline de Pr√©-processamento\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "features = ['Year', 'Distance (in meters)', 'Stroke', 'Relay?', 'Gender', 'Team', 'Distance_value']\nX = df[features].copy()\ny = df['Medalha']\n\ncat_cols = ['Stroke', 'Gender', 'Team']\nnum_cols = ['Year', 'Relay?', 'Distance_value']\n\npreprocessor = ColumnTransformer([\n    ('num', StandardScaler(), num_cols),\n    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n])\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.30, random_state=RANDOM_STATE, stratify=y\n)\n\nprint(\"Treino/Teste:\", X_train.shape, X_test.shape)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Baseline ‚Äî Regress√£o Log√≠stica\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "logreg = Pipeline([\n    ('preprocessor', preprocessor),\n    ('classifier', LogisticRegression(max_iter=1000, random_state=RANDOM_STATE))\n])\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)\ny_prob = logreg.predict_proba(X_test)[:,1]\n\nprint(\"Acur√°cia:\", round(accuracy_score(y_test, y_pred),3))\nprint(classification_report(y_test, y_pred))\nprint(\"ROC-AUC:\", round(roc_auc_score(y_test, y_prob),3))\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Compara√ß√£o de Modelos ‚Äî LogReg √ó RandomForest √ó XGBoost\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "modelos = {\n    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),\n    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE),\n    \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE)\n}\n\nresultados = {}\nfor nome, clf in modelos.items():\n    pipe = Pipeline([('preprocessor', preprocessor), ('classifier', clf)])\n    pipe.fit(X_train, y_train)\n    yp = pipe.predict(X_test)\n    ypb = pipe.predict_proba(X_test)[:,1]\n    d = classification_report(y_test, yp, output_dict=True)\n    resultados[nome] = {\n        \"Acur√°cia\": accuracy_score(y_test, yp),\n        \"Precis√£o (classe 1)\": d['1']['precision'],\n        \"Recall (classe 1)\": d['1']['recall'],\n        \"F1 (classe 1)\": d['1']['f1-score'],\n        \"ROC-AUC\": roc_auc_score(y_test, ypb)\n    }\n\npd.DataFrame(resultados).T.sort_values(\"ROC-AUC\", ascending=False)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Tuning ‚Äî XGBoost (RandomizedSearchCV)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "param_dist = {\n    \"classifier__n_estimators\": [200, 300, 500, 800],\n    \"classifier__max_depth\": [3, 4, 5, 6, 8],\n    \"classifier__learning_rate\": [0.01, 0.05, 0.1, 0.2],\n    \"classifier__subsample\": [0.7, 0.8, 0.9, 1.0],\n    \"classifier__colsample_bytree\": [0.7, 0.8, 0.9, 1.0],\n    \"classifier__gamma\": [0, 1, 5],\n    \"classifier__min_child_weight\": [1, 3, 5],\n    \"classifier__reg_lambda\": [1, 5, 10]\n}\n\nxgb_base = xgb.XGBClassifier(eval_metric='logloss', random_state=RANDOM_STATE, tree_method='hist')\n\npipe_xgb = Pipeline([('preprocessor', preprocessor), ('classifier', xgb_base)])\n\nsearch = RandomizedSearchCV(\n    pipe_xgb, param_distributions=param_dist, n_iter=30, scoring=\"f1\",\n    cv=5, random_state=RANDOM_STATE, n_jobs=-1, verbose=1\n)\nsearch.fit(X_train, y_train)\nbest_model = search.best_estimator_\nprint(\"Melhor combina√ß√£o:\", search.best_params_)\n\ny_pred = best_model.predict(X_test)\ny_prob = best_model.predict_proba(X_test)[:, 1]\n\nprint(\"Acur√°cia:\", round(accuracy_score(y_test, y_pred),3))\nprint(classification_report(y_test, y_pred))\nprint(\"ROC-AUC:\", round(roc_auc_score(y_test, y_prob),3))\n\ncm = confusion_matrix(y_test, y_pred)\nConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_model.classes_).plot(cmap=plt.cm.Blues)\nplt.title(\"Matriz de Confus√£o - XGBoost (tuned, thr=0.50)\")\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 9. Ajuste de Threshold (decis√£o)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def avalia_threshold(y_true, y_scores, thresholds):\n    rows = []\n    for t in thresholds:\n        yp = (y_scores >= t).astype(int)\n        prec, rec, f1, _ = precision_recall_fscore_support(y_true, yp, average='binary')\n        rows.append([t, prec, rec, f1])\n    return pd.DataFrame(rows, columns=[\"threshold\",\"precision_1\",\"recall_1\",\"f1_1\"])\n\nths = np.linspace(0.20, 0.80, 25)\nthr_df = avalia_threshold(y_test, y_prob, ths)\nthr_df\n\n# Aplicar threshold final\nTHRESHOLD = 0.40\ny_pred_thr = (y_prob >= THRESHOLD).astype(int)\n\nprint(f\"\\nThreshold fixado em {THRESHOLD}\")\nprint(\"Acur√°cia:\", round(accuracy_score(y_test, y_pred_thr),3))\nprint(classification_report(y_test, y_pred_thr))\n\ncm = confusion_matrix(y_test, y_pred_thr)\nConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_model.classes_).plot(cmap=plt.cm.Blues)\nplt.title(f\"Matriz - XGBoost (threshold={THRESHOLD})\")\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 10. Import√¢ncia das Vari√°veis (XGBoost)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Extrair nomes de features ap√≥s o preprocessor\nfeat_names = best_model.named_steps['preprocessor'].get_feature_names_out()\nimportances = best_model.named_steps['classifier'].feature_importances_\n\nfi = pd.DataFrame({\"feature\": feat_names, \"importance\": importances}).sort_values(\"importance\", ascending=False)\ndisplay(fi.head(20))\n\n# Plot simples com matplotlib (top 15)\ntopk = fi.head(15)[::-1]  # invert for horizontal plot\nplt.figure(figsize=(8,6))\nplt.barh(topk[\"feature\"], topk[\"importance\"])\nplt.title(\"Import√¢ncia das vari√°veis ‚Äî XGBoost\")\nplt.tight_layout()\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 11. Experimentos de Robustez (opcional)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# A) Sem Team\nXb = df[['Year','Distance (in meters)','Stroke','Relay?','Gender','Distance_value']].copy()\nyb = df['Medalha']\n\ncat_b = ['Stroke','Gender']\nnum_b = ['Year','Relay?','Distance_value']\n\npre_b = ColumnTransformer([('num', StandardScaler(), num_b),\n                           ('cat', OneHotEncoder(handle_unknown='ignore'), cat_b)])\n\nXtr_b, Xte_b, ytr_b, yte_b = train_test_split(Xb, yb, test_size=0.30, random_state=RANDOM_STATE, stratify=yb)\npipe_b = Pipeline([('pre', pre_b), ('clf', xgb.XGBClassifier(eval_metric='logloss', random_state=RANDOM_STATE, tree_method='hist'))])\npipe_b.fit(Xtr_b, ytr_b)\nyp_b  = pipe_b.predict(Xte_b)\nypb_b = pipe_b.predict_proba(Xte_b)[:,1]\n\nprint(\"Acur√°cia (sem Team):\", round(accuracy_score(yte_b, yp_b),3))\nprint(classification_report(yte_b, yp_b))\nprint(\"ROC-AUC:\", round(roc_auc_score(yte_b, ypb_b),3))\n\n# B) Agrupar Team: Top-N vs OTHER (definido no TREINO)\nXg = df[['Year','Distance (in meters)','Stroke','Relay?','Gender','Team','Distance_value']].copy()\nyg = df['Medalha']\nXtr_g, Xte_g, ytr_g, yte_g = train_test_split(Xg, yg, test_size=0.30, random_state=RANDOM_STATE, stratify=yg)\n\nmedals_by_team = (pd.DataFrame({\"Team\": Xtr_g['Team'].values, \"Medalha\": ytr_g.values})\n                  .groupby('Team')['Medalha'].mean().sort_values(ascending=False))\ntop_teams = set(medals_by_team.head(TOP_N).index)\n\ndef map_team(team): return team if team in top_teams else \"OTHER\"\nXtr_g['Team_grouped'] = Xtr_g['Team'].map(map_team)\nXte_g['Team_grouped']  = Xte_g['Team'].map(map_team)\n\ncat_g = ['Stroke','Gender','Team_grouped']\nnum_g = ['Year','Relay?','Distance_value']\npre_g = ColumnTransformer([('num', StandardScaler(), num_g),\n                           ('cat', OneHotEncoder(handle_unknown='ignore'), cat_g)])\n\npipe_g = Pipeline([('pre', pre_g), ('clf', xgb.XGBClassifier(eval_metric='logloss', random_state=RANDOM_STATE, tree_method='hist',\n                                                             n_estimators=300, max_depth=6, learning_rate=0.1,\n                                                             subsample=0.7, colsample_bytree=1.0, gamma=1, min_child_weight=3, reg_lambda=10))])\npipe_g.fit(Xtr_g, ytr_g)\nyp_g  = pipe_g.predict(Xte_g)\nypb_g = pipe_g.predict_proba(Xte_g)[:,1]\n\nprint(\"\\nAcur√°cia (Top-N pa√≠ses):\", round(accuracy_score(yte_g, yp_g),3))\nprint(classification_report(yte_g, yp_g))\nprint(\"ROC-AUC:\", round(roc_auc_score(yte_g, ypb_g),3))\n\n# Threshold aplicado (0.40)\nyp_thr_g = (ypb_g >= THRESHOLD).astype(int)\nprint(\"\\nCom threshold=0.40:\")\nprint(\"Acur√°cia:\", round(accuracy_score(yte_g, yp_thr_g),3))\nprint(classification_report(yte_g, yp_thr_g))\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 12. Resultados & Conclus√µes\n\n- **Modelo final:** **XGBoost** (com *tuning*) + **threshold = 0.40** (prioriza recall de medalhistas).\n- **Principais m√©tricas esperadas (refer√™ncia):** acur√°cia ~0.62, ROC-AUC ~0.65, recall(classe 1) ~0.55.\n- **Vari√°veis mais relevantes:** `Team_*` (pa√≠s, especialmente EUA), `Relay?`, `Stroke`, `Distance_value`, `Year`.\n- **Trade-off controlado pelo threshold:** aumentar recall de medalhistas implica reduzir precis√£o/ acur√°cia ‚Äî decis√£o intencional do neg√≥cio.\n\n**Limita√ß√µes e melhorias:**\n1) Depend√™ncia de `Team` (tradi√ß√£o hist√≥rica) ‚Äî avaliar *target encoding* com CV.  \n2) Valida√ß√£o temporal (treinar em anos antigos, testar em anos recentes).  \n3) Calibra√ß√£o de probabilidades (Platt/Isot√¥nica) e an√°lise por evento espec√≠fico.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 13. Checklist (atendido)\n\n- **Defini√ß√£o do problema:** clara e com hip√≥teses.  \n- **Prepara√ß√£o de dados:** split estratificado; engenharia (`Distance_value`); one-hot + padroniza√ß√£o.  \n- **Modelagem:** baseline + compara√ß√£o (LogReg, RF, XGB); *tuning* por CV.  \n- **Otimiza√ß√£o:** RandomizedSearchCV com espa√ßo e melhores par√¢metros registrados.  \n- **Avalia√ß√£o:** m√©tricas adequadas; matriz de confus√£o; *threshold sweep* documentado.  \n- **Boas pr√°ticas:** seeds; pipeline; execu√ß√£o fim-a-fim via URL p√∫blica; documenta√ß√£o por se√ß√£o.\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}